# dynamic_risk_road_prediction
利用GBDT+LR预测动态高危路段
3总体思路
数据获取
数据清洗：将不同类型的数据合并在一起，对于缺失值数据进行处理，同时对于分类特征进行onehot编码
特征工程：对于数值特征进行平滑处理，选择出与主题相关的特征
数据建模：选择合适的算法，根据训练集训练出一个模型
模型评估：将模型运用在测试集中，选择合适的指标（准确率/召回率/F值等）来评估模型
效果验证：将预测结果与实际情况进行比较，实际评估模型的有效性
模型改进：人工分析实际中预测错误的数据，然后提出模型的改进建议

4动态高危路段预测分析
4.1确定高危路段的含义
方法：两步聚类法。两步聚类算法是在SPSS Modeler中使用的一种聚类算法，是BIRCH层次聚类算法的改进版本。可以应用于混合属性数据集的聚类，同时加入了自动确定最佳簇数量的机制，使得方法更加实用。
两步聚类算法，顾名思义分为两个阶段：
1）预聚类（pre-clustering）阶段。采用了BIRCH算法中CF树生长的思想，逐个读取数据集中数据点，在生成CF树的同时，预先聚类密集区域的数据点，形成诸多的小的子簇（sub-cluster）。
2）聚类（clustering）阶段。以预聚类阶段的结果——子簇为对象，利用凝聚法（agglomerative hierarchical clustering method），逐个地合并子簇，直到期望的簇数量

步骤：遍历每段路（2公里），是否有桥梁、是否有管制、管制原因、月份、时刻、天气。然后将发生事故的数据进行两步聚类（采用两步聚类主要是因为特征中有数值型数据与无序离散型数据），划分为两类，一类是随机发生的事故的路段，另一类的高危路段，然后对动态高危路段进行划分。

工具：SPSS modeler
4.2数据获取
ahgs数据库
表：bridgedata、gaosu_event、tunneldata
天气数据
时间数据
4.3构造特征集
4．3．1原始特征
遍历所有道路，每2公里作为一个路段
对于每个路段，特征集分为几大类型：时间、道路、天气
具体特征：
时间：将一天划分为24小时，每小时作为一个特征变量（int）、季节（不同季节早上6点的可见度是不一样的）、是否是节假日（交通流量的一个侧面反映）
道路：是否管制（Boolean）、管制原因、管制等级、是否施工（Boolean）、包含桥梁（Boolean）、是否有隧道（Boolean）
事故：该路段在此时刻发生过的事故数
天气：湿度（double），温度（double），能见度（int），风速(int)，风向（int）
4．3．2组合特征
方法：由于现有的特征太少，利用GBDT构造组合特征：先用已有特征训练GBDT模型，然后利用GBDT模型学习到的树来构造新特征，最后把这些新特征加入原有特征一起训练模型。构造的新特征向量是取值0/1的，向量的每个元素对应于GBDT模型中树的叶子结点。当一个样本点通过某棵树最终落在这棵树的一个叶子结点上，那么在新特征向量中这个叶子结点对应的元素值为1，而这棵树的其他叶子结点对应的元素值为0。新特征向量的长度等于GBDT模型里所有树包含的叶子结点数之和。
工具：Python的数据挖掘库中包含了GradientBoostingClassifier和GradientBoostingRegressor，都可以从sklearn.ensemble里调用。
Estimators提供了一系列参数来控制拟合，GBRT里重要的参数如下：回归树的数量（n_estimators）、每棵独立树的深度(max_depth)、损失函数(loss)、学习速率(learning_rate)

4.4构造数据集
给所有路段附上上述属性，然后对于标签，高危路段标为1（称为正样本），非高危路段标为0（称为负样本）。
如何打标签：首先给所有的路段标记为0，然后依据聚类结果，将划分的路段去遍历得到的高危路段集。

4.5处理正负样本不均衡
方法一：对负样本进行下采样，即随机抽取一部分负样本，使得正样本与负样本的比例满足1:10（暂定，最终比例需要根据实际情况确定），以此得到的结果作为最终的数据集。
方法二：进行再缩放，即假设现有的数据就是真实样本总体的无偏采样。令m+表示数据集中正例数目（高危路段），m-表示反例数目，则观测几率是m+/m-,只要分类器的预测几率高于观测几率就判定为正例：y/(1-y)>m^+/m^- 则预测为正例，其中y表示样本属于正例的概率。
划分训练集与测试集：以75%作为训练集，25%作为测试集

4.6分类算法（预测）
4.6.1算法
逻辑回归
4.6.2可能出现的结果
（1）过拟合：模型在训练集上的效果较好，但是在测试集上效果很差
原因：过拟合说明模型学到了一些属于个别样本的特殊属性，
解决方法：
1）重新清洗数据，导致过拟合的一个原因也有可能是数据不纯导致的，如果出现了过拟合就需要我们重新清洗数据。
2）增大数据的训练量，还有一个原因就是我们用于训练的数据量太小导致的，训练数据占总数据的比例过小。
3）采用正则化方法。正则化方法包括L0正则、L1正则和L2正则，而正则一般是在目标函数之后加上对于的范数。但是在机器学习中一般使用L2正则。
L0范数是指向量中非0的元素的个数。L1范数是指向量中各个元素绝对值之和，也叫“稀疏规则算子”（Lasso regularization）。两者都可以实现稀疏性，既然L0可以实现稀疏，为什么不用L0，而要用L1呢？一是因为L0范数很难优化求解（NP难问题），二是L1范数是L0范数的最优凸近似，而且它比L0范数要容易优化求解。L2范数是指向量各元素的平方和然后求平方根。可以使得W的每个元素都很小，都接近于0，但与L1范数不同，它不会让它等于0，而是接近于0。L2正则项起到使得参数w变小加剧的效果，但是为什么可以防止过拟合呢？一个通俗的理解便是：更小的参数值w意味着模型的复杂度更低，对训练数据的拟合刚刚好（奥卡姆剃刀），不会过分拟合训练数据，从而使得不会过拟合，以提高模型的泛化能力。还有就是看到有人说L2范数有助于处理 condition number不好的情况下矩阵求逆很困难的问题。

（2）欠拟合：模型在训练集上的效果很不好
改进：说明数据集样本量不够，或者特征数目过少，根据实际情况增加样本量或者对特征集进行修改
解决方法：
1）添加其他特征项，有时候我们模型出现欠拟合的时候是因为特征项不够导致的，可以添加其他特征项来很好地解决。例如，“组合”、“泛化”、“相关性”三类特征是特征添加的重要手段。
2）添加多项式特征，这个在机器学习算法里面用的很普遍，例如将线性模型通过添加二次项或者三次项使模型泛化能力更强。
3）减少正则化参数，正则化的目的是用来防止过拟合的，但是现在模型出现了欠拟合，则需要减少正则化参数。


4.8效果评估
目标是为了找出高危路段，由于正负样本的不均衡，评估时只考虑高危路段类，采用召回率、准确率和F1值。该项目的目的是预测出动态高危路段，为交通部门的管理工作以及司机的出行提供指导，因此要可能找出所有的动态高危路段，容忍把非动态高危路段预测为高危路段，即在效果评估时召回率是更加重要的指标。首先明确几个字符的含义：
n:预测是高危路段而且实际上是高危路段
N：预测是高危路段类
M:实际是高危路段类
因此准确率表示为Precision(高危路段类)=n/N，召回率表示为Recall(高危路段类)=n/M，F值为F=1/(∂ 1/precision+(1-∂)1/recall)，其中∂在[0，1]之间取值，当∂=0.5时，准确率与召回率同等重要，当∂>0.5时，准确率更加重要。在实际实施过程中，采用∂=0.4

4.9 模型验证与改进
在实际算法实施过程中，基于一个思想：预测的动态高危路段不一定会发生事故，但是事故一定会发生在预测得到的高危路段上。因此用N表示该时刻发生在预测得到的高危路段上的事故数，用M表示该时刻实际发生的事故数，则N/M表示模型实际效果。
对于那些没有发生在预测的高危路段上的事故，将事故的详细信息进行分析，考察是否是偶然发生的事故，还是说是因为道路天气等因素造成的，如果是后者，则意味着模型预测错误，需要根据这些记录对模型进行改进。

4.10实验实施以及结果分析
以安徽省20170814至20170827的数据构造数据集验证算法，现有的特征包括时刻、是否有桥梁、是否有隧道、是否施工、是否管制、管制原因、管制等级
、温度、湿度、可见度、风速、风向、道路该时刻发生过的事故数，包括离散型特征与数值型特征。
对发生事故的数据进行两步聚类后，对数据集打上标签。
为了节省训练时间，在处理正负样本不平衡的问题上对负样本进行下采样，最终得到的正负样本比例为1:1.然后分别取正负样本中的75%作为训练集，剩余的作为测试集，其中训练集有 样本，测试集有 样本。
对离散特征进行向量化处理，对数值型特征进行标准化处理
将训练集中的50%作为GDBT的训练集，训练出一个可以构造组合特征的GBDT模型，然后在余下的50%训练集上实施GBDT，将其得到的稀疏特征与原有特征一起作为逻辑回归模型训练集中的特征，逻辑回归模型的求解采用L-BFGS,为了防止过拟合，采用了L2正则化。
最后是模型评估，将得到的GBDT模型和逻辑回归模型实施在测试集上，然后用准确率与召回率、F1值来评估结果。
由于需要对负样本进行下采样，该过程是随机，因此不同的采样结果会影响模型的效果，在实际实施过程中，发现在测试集上效果不是稳定（不同的采样结果得到的模型会有不同的性能）

5动态高危路段成因分析
	交通管理中的两个关键问题，一是找出那些高危路段，另一方面是确定动态高危路段的成因，为交通部门提供指导。思路是通过挖掘算法对动态高危路段的诸多相关因素进行关联分析，寻找事故集中隐含着的强关联规则，发掘有实际价值的事故诱因组合。通过对动态高危路段关联分析，解决“为什么”的问题，为改善交通提供科学依据。
关联规则挖掘(Association Rule Mining)是知识发现中的一个重大问题，它是由Agrawal，Imielinski和Swami在1933年最早共同提出的，也是目前数据挖掘领域里最为活跃的研究方向。它主要用于发现数据库内不同项目集的相关性，利用各种挖掘算法提取出数据集中的所有频繁模式，找出其相应的关联规则。
需要注意的是，动态高危路段的数据模型是多维的，而经典Apriori算法是建立在单维数据模型上进行关联规则挖掘的，不适用于对多维数据进行挖掘。因此需要对Apriori算法进行了一定改进。我们使用谓词逻辑来处理交通事故多维数据，谓词逻辑是多维数据结构模式形式化描述与求解的重要方式。将数据模型的每个维度看作是一个谓词，这样我们就可以通过Apriori算法搜索出频繁谓词集，然后通过频繁谓词集挖掘规则。
对于发生的动态高危路段，可以用其属性去遍历得到的规则，找出满足条件的规则，作为高危路段的成因。（不足：可能有些动态高危路段的成因找不到）
6.存在的问题
1、目前的特征比较少，后续需要补充是否是节假日、路段的车道数、路段是否是路口（下高速或者上高速）、路段的车流量数据、路段在该时刻的平均速度，距离服务区的距离、车辆数、不同车型的比例、该城市人口密度、夜晚的照明情况等特征
2、道路的天气数据大量缺失，大部分道路匹配不到对应的天气数据
3、目前能够查询到天气的道路只占了很少一部分，需要补充天气数据
4、代码运行速度慢
5、如果要进行实时预测，构造特征上存在问题
6、模型的预测性能不好
7、对预测为高危路段的路段如何给出原因以及合理的解决方案上还存在问题。

后续打算尝试的方法
1、在动态高危路段的标签确定上，可以考虑将整个问题作为一个半监督的问题。
首先将整个数据集分为两类，一类是发生事故的路段（数据集A），一类是未发生事故的路段（数据集B）。
对发生事故的高危路段（数据集A）进行聚类，然后选择其中的某一类（或者某几类）作为高位路段，打上标签1，剩下的打上标签0.
对于数据集B中路段，视为未标注的路段，然后运用标签传播算法给这些路段打上标签

2.在算法的选择上，尝试运用排序学习的算法，动态高危路段是处于前50（暂不确定）的路段

3.在处理正负样本不均衡的问题上，可以考虑对动态高危路段这个样本进行上采样，观察是否可以提高模型的准确率

考虑：目前补充特征很有难度，正在考虑换个思路去做，在只有时间、地点和事故的情况想想其他的办法

